{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import os.path\n",
    "import random\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as data\n",
    "import ntpath\n",
    "import sys\n",
    "from skimage.transform import resize\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "import functools\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "import importlib\n",
    "from collections import OrderedDict\n",
    "import shutil\n",
    "from util import util\n",
    "import imageio\n",
    "from util import html\n",
    "from util.visualizer import save_images\n",
    "import torch.multiprocessing as mp\n",
    "from util.visualizer import Visualizer\n",
    "\n",
    "if mp.get_start_method() != 'spawn':\n",
    "    mp.set_start_method('spawn')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseDataset(data.Dataset):\n",
    "    def __init__(self):\n",
    "        super(BaseDataset, self).__init__()\n",
    "\n",
    "    def name(self):\n",
    "        return \"BaseDataset\"\n",
    "\n",
    "    @staticmethod\n",
    "    def modify_commandline_options(parser, is_train):\n",
    "        return parser\n",
    "\n",
    "    def initialize(self, opt):\n",
    "        pass\n",
    "\n",
    "    def __len__(self):\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform(opt):\n",
    "    transform_list = []\n",
    "    if opt.resize_or_crop == \"resize_and_crop\":\n",
    "        osize = [opt.loadSize, opt.loadSize]\n",
    "        transform_list.append(transforms.Resize(osize, Image.BICUBIC))\n",
    "        transform_list.append(transforms.RandomCrop(opt.fineSize))\n",
    "    elif opt.resize_or_crop == \"crop\":\n",
    "        transform_list.append(transforms.RandomCrop(opt.fineSize))\n",
    "    elif opt.resize_or_crop == \"scale_width\":\n",
    "        transform_list.append(\n",
    "            transforms.Lambda(lambda img: __scale_width(img, opt.fineSize))\n",
    "        )\n",
    "    elif opt.resize_or_crop == \"scale_width_and_crop\":\n",
    "        transform_list.append(\n",
    "            transforms.Lambda(lambda img: __scale_width(img, opt.loadSize))\n",
    "        )\n",
    "        transform_list.append(transforms.RandomCrop(opt.fineSize))\n",
    "    elif opt.resize_or_crop == \"none\":\n",
    "        transform_list.append(transforms.Lambda(lambda img: __adjust(img)))\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"--resize_or_crop %s is not a valid option.\" % opt.resize_or_crop\n",
    "        )\n",
    "\n",
    "    if opt.isTrain and not opt.no_flip:\n",
    "        transform_list.append(transforms.RandomHorizontalFlip())\n",
    "\n",
    "    transform_list += [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ]\n",
    "    return transforms.Compose(transform_list)\n",
    "\n",
    "\n",
    "# just modify the width and height to be multiple of 4\n",
    "def __adjust(img):\n",
    "    ow, oh = img.size\n",
    "\n",
    "    # the size needs to be a multiple of this number,\n",
    "    # because going through generator network may change img size\n",
    "    # and eventually cause size mismatch error\n",
    "    mult = 4\n",
    "    if ow % mult == 0 and oh % mult == 0:\n",
    "        return img\n",
    "    w = (ow - 1) // mult\n",
    "    w = (w + 1) * mult\n",
    "    h = (oh - 1) // mult\n",
    "    h = (h + 1) * mult\n",
    "\n",
    "    if ow != w or oh != h:\n",
    "        __print_size_warning(ow, oh, w, h)\n",
    "\n",
    "    return img.resize((w, h), Image.BICUBIC)\n",
    "\n",
    "\n",
    "def __scale_width(img, target_width):\n",
    "    ow, oh = img.size\n",
    "\n",
    "    # the size needs to be a multiple of this number,\n",
    "    # because going through generator network may change img size\n",
    "    # and eventually cause size mismatch error\n",
    "    mult = 4\n",
    "    assert target_width % mult == 0, (\n",
    "        \"the target width needs to be multiple of %d.\" % mult\n",
    "    )\n",
    "    if ow == target_width and oh % mult == 0:\n",
    "        return img\n",
    "    w = target_width\n",
    "    target_height = int(target_width * oh / ow)\n",
    "    m = (target_height - 1) // mult\n",
    "    h = (m + 1) * mult\n",
    "\n",
    "    if target_height != h:\n",
    "        __print_size_warning(target_width, target_height, w, h)\n",
    "\n",
    "    return img.resize((w, h), Image.BICUBIC)\n",
    "\n",
    "\n",
    "def __print_size_warning(ow, oh, w, h):\n",
    "    if not hasattr(__print_size_warning, \"has_printed\"):\n",
    "        print(\n",
    "            \"The image size needs to be a multiple of 4. \"\n",
    "            \"The loaded image size was (%d, %d), so it was adjusted to \"\n",
    "            \"(%d, %d). This adjustment will be done to all images \"\n",
    "            \"whose sizes are not multiples of 4\" % (ow, oh, w, h)\n",
    "        )\n",
    "        __print_size_warning.has_printed = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseDataLoader():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def initialize(self, opt):\n",
    "        self.opt = opt\n",
    "        pass\n",
    "\n",
    "    def load_data(self):\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AffineGANDataset(BaseDataset):\n",
    "    @staticmethod\n",
    "    def modify_commandline_options(parser, is_train):\n",
    "        return parser\n",
    "\n",
    "    def pre_process_img(self, path, convertRGB, w_offset, h_offset, flip):\n",
    "        if not os.path.exists(path):\n",
    "            if convertRGB:\n",
    "                return np.zeros(\n",
    "                    (self.opt.fineSize, self.opt.fineSize, 3), dtype=np.float32\n",
    "                )\n",
    "            else:\n",
    "                return np.zeros((self.opt.fineSize, self.opt.fineSize), dtype=np.float32)\n",
    "\n",
    "        image = Image.open(path)\n",
    "        if convertRGB:\n",
    "            image = image.convert(\"RGB\")\n",
    "        else:\n",
    "            image = image.convert(\"L\")\n",
    "        image = image.resize((self.opt.loadSize, self.opt.loadSize), Image.BICUBIC)\n",
    "        image = np.array(image)\n",
    "        if not convertRGB:\n",
    "            image = image[..., np.newaxis]\n",
    "            image = np.tile(image, [1, 1, 3])\n",
    "        image = transforms.ToTensor()(image)\n",
    "        image = image[\n",
    "            :,\n",
    "            h_offset : h_offset + self.opt.fineSize,\n",
    "            w_offset : w_offset + self.opt.fineSize,\n",
    "        ]\n",
    "        image = transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))(image)\n",
    "        if not convertRGB:\n",
    "            image[image < 0.5] = 0.0\n",
    "            image[image >= 0.5] = 1.0\n",
    "        if flip:\n",
    "            idx = torch.LongTensor([i for i in range(image.size(2) - 1, -1, -1)])\n",
    "            image = image.index_select(2, idx)\n",
    "\n",
    "        return image\n",
    "\n",
    "    def initialize(self, opt):\n",
    "        self.opt = opt\n",
    "        self.dir_AB = os.path.join(opt.dataroot, opt.phase, \"img\")\n",
    "        self.AB_paths = []\n",
    "\n",
    "        if not self.opt.no_patch:\n",
    "            self.dir_AB_patch = os.path.join(opt.dataroot, opt.phase, \"patch\")\n",
    "            self.AB_patch = []\n",
    "\n",
    "        video_names = sorted([f for f in os.listdir(self.dir_AB) if \".\" not in f])\n",
    "        self.sample_num = len(video_names)\n",
    "\n",
    "        for sample_idx in range(self.sample_num):\n",
    "            sample_name = video_names[sample_idx]\n",
    "            self.AB_paths.append(os.path.join(self.dir_AB, sample_name))\n",
    "            if not self.opt.no_patch:\n",
    "                self.AB_patch.append(os.path.join(self.dir_AB_patch, sample_name))\n",
    "\n",
    "        assert opt.resize_or_crop == \"resize_and_crop\"\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        w_offset = random.randint(0, max(0, self.opt.loadSize - self.opt.fineSize - 1))\n",
    "        h_offset = random.randint(0, max(0, self.opt.loadSize - self.opt.fineSize - 1))\n",
    "\n",
    "        AB_path = self.AB_paths[index]\n",
    "        img_names = sorted([f for f in os.listdir(AB_path)])\n",
    "\n",
    "        flip = (not self.opt.no_flip) and random.random() < 0.5\n",
    "\n",
    "        A_name = os.path.join(AB_path, img_names[0])\n",
    "        A = self.pre_process_img(A_name, True, w_offset, h_offset, flip)\n",
    "        ret_dict = {\"A\": A, \"A_paths\": AB_path}\n",
    "\n",
    "        if self.opt.isTrain:\n",
    "            if not self.opt.no_patch:\n",
    "                # When Testing, the model doesn't need patches\n",
    "                A_name = os.path.join(self.AB_patch[index], img_names[0])\n",
    "                A_patch = self.pre_process_img(A_name, False, w_offset, h_offset, flip)\n",
    "                ret_dict[\"A_patch\"] = A_patch\n",
    "                B_patch_list = []\n",
    "\n",
    "            B_list = []\n",
    "            np.random.seed()\n",
    "            img_sample = range(1, len(img_names))\n",
    "            img_sample = np.random.choice(\n",
    "                img_sample, self.opt.train_imagenum, replace=True\n",
    "            )\n",
    "            for img_idx in range(self.opt.train_imagenum):\n",
    "                sample_image_idx = img_sample[img_idx]\n",
    "\n",
    "                B_name = os.path.join(AB_path, img_names[sample_image_idx])\n",
    "                B = self.pre_process_img(B_name, True, w_offset, h_offset, flip)\n",
    "\n",
    "                B_list.append(B)\n",
    "                if not self.opt.no_patch:\n",
    "                    B_name = os.path.join(\n",
    "                        self.AB_patch[index], img_names[sample_image_idx]\n",
    "                    )\n",
    "                    B_patch = self.pre_process_img(\n",
    "                        B_name, False, w_offset, h_offset, flip\n",
    "                    )\n",
    "                    B_patch_list.append(B_patch)\n",
    "\n",
    "            ret_dict[\"B_list\"] = B_list\n",
    "            if not self.opt.no_patch:\n",
    "                ret_dict[\"B_patch_list\"] = B_patch_list\n",
    "\n",
    "        return ret_dict\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.sample_num\n",
    "\n",
    "    def name(self):\n",
    "        return \"AffineGANDataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_dataset_using_name(dataset_name):\n",
    "    dataset = None\n",
    "    if dataset_name.lower() == \"affinegan\":\n",
    "        dataset = AffineGANDataset\n",
    "\n",
    "    if dataset is None:\n",
    "        print(\n",
    "            \"There should be a subclass of BaseDataset with class name that matches %s in lowercase.\"\n",
    "            % dataset_name\n",
    "        )\n",
    "        exit(0)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def get_option_setter(dataset_name):\n",
    "    dataset_class = find_dataset_using_name(dataset_name)\n",
    "    return dataset_class.modify_commandline_options\n",
    "\n",
    "\n",
    "def create_dataset(opt):\n",
    "    dataset = find_dataset_using_name(opt.dataset_mode)\n",
    "    instance = dataset()\n",
    "    instance.initialize(opt)\n",
    "    print(\"dataset [%s] was created\" % (instance.name()))\n",
    "    return instance\n",
    "\n",
    "\n",
    "def CreateDataLoader(opt):\n",
    "    data_loader = CustomDatasetDataLoader()\n",
    "    print(data_loader.name())\n",
    "    data_loader.initialize(opt)\n",
    "    return data_loader\n",
    "\n",
    "\n",
    "class CustomDatasetDataLoader(BaseDataLoader):\n",
    "    def name(self):\n",
    "        return \"CustomDatasetDataLoader\"\n",
    "\n",
    "    def initialize(self, opt):\n",
    "        BaseDataLoader.initialize(self, opt)\n",
    "        self.dataset = create_dataset(opt)\n",
    "        self.dataloader = torch.utils.data.DataLoader(\n",
    "            self.dataset,\n",
    "            batch_size=opt.batch_size,\n",
    "            shuffle=not opt.serial_batches,\n",
    "            num_workers=0,\n",
    "        )\n",
    "\n",
    "    def load_data(self):\n",
    "        return self\n",
    "\n",
    "    def __len__(self):\n",
    "        return min(len(self.dataset), self.opt.max_dataset_size)\n",
    "\n",
    "    def __iter__(self):\n",
    "        for i, data in enumerate(self.dataloader):\n",
    "            if i * self.opt.batch_size >= self.opt.max_dataset_size:\n",
    "                break\n",
    "            yield data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANLoss(nn.Module):\n",
    "    def __init__(self, use_lsgan=True, target_real_label=1.0, target_fake_label=0.0):\n",
    "        super(GANLoss, self).__init__()\n",
    "        self.register_buffer('real_label', torch.tensor(target_real_label))\n",
    "        self.register_buffer('fake_label', torch.tensor(target_fake_label))\n",
    "        if use_lsgan:\n",
    "            self.loss = nn.MSELoss()\n",
    "        else:\n",
    "            self.loss = nn.BCELoss()\n",
    "\n",
    "    def get_target_tensor(self, input, target_is_real):\n",
    "        if target_is_real:\n",
    "            target_tensor = self.real_label\n",
    "        else:\n",
    "            target_tensor = self.fake_label\n",
    "        return target_tensor.expand_as(input)\n",
    "\n",
    "    def __call__(self, input, target_is_real):\n",
    "        target_tensor = self.get_target_tensor(input, target_is_real)\n",
    "        return self.loss(input, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetGenerator(nn.Module):\n",
    "    def __init__(self, input_nc, output_nc, ngf=64, norm_layer=nn.BatchNorm2d, use_dropout=False, n_blocks=6,\n",
    "                 padding_type='reflect'):\n",
    "        assert (n_blocks >= 0)\n",
    "        super(ResnetGenerator, self).__init__()\n",
    "        self.input_nc = input_nc\n",
    "        self.output_nc = output_nc\n",
    "        self.ngf = ngf\n",
    "        if type(norm_layer) == functools.partial:\n",
    "            use_bias = norm_layer.func == nn.InstanceNorm2d\n",
    "        else:\n",
    "            use_bias = norm_layer == nn.InstanceNorm2d\n",
    "        n_downsampling = 2\n",
    "\n",
    "        down_base = [nn.ReflectionPad2d(3),\n",
    "                 nn.Conv2d(input_nc, ngf, kernel_size=7, padding=0,\n",
    "                           bias=use_bias),\n",
    "                 norm_layer(ngf),\n",
    "                 nn.ReLU(True)]\n",
    "        down_res = [nn.ReflectionPad2d(3),\n",
    "                      nn.Conv2d(input_nc, ngf, kernel_size=7, padding=0,\n",
    "                                bias=use_bias),\n",
    "                      norm_layer(ngf),\n",
    "                      nn.ReLU(True)]\n",
    "        for i in range(n_downsampling):\n",
    "            mult = 2 ** i\n",
    "            down_base += [nn.Conv2d(ngf * mult, ngf * mult * 2, kernel_size=3,\n",
    "                                stride=2, padding=1, bias=use_bias),\n",
    "                      norm_layer(ngf * mult * 2),\n",
    "                      nn.ReLU(True)]\n",
    "            down_res += [nn.Conv2d(ngf * mult, ngf * mult * 2, kernel_size=3,\n",
    "                                     stride=2, padding=1, bias=use_bias),\n",
    "                           norm_layer(ngf * mult * 2),\n",
    "                           nn.ReLU(True)]\n",
    "\n",
    "        mult = 2 ** n_downsampling\n",
    "        for i in range(n_blocks):\n",
    "            down_base += [ResnetBlock(ngf * mult, padding_type=padding_type, norm_layer=norm_layer, use_dropout=use_dropout,\n",
    "                                  use_bias=use_bias)]\n",
    "            down_res += [\n",
    "                ResnetBlock(ngf * mult, padding_type=padding_type, norm_layer=norm_layer, use_dropout=use_dropout,\n",
    "                            use_bias=use_bias)]\n",
    "        up_all = []\n",
    "        for i in range(n_downsampling):\n",
    "            mult = 2 ** (n_downsampling - i)\n",
    "            up_all += [nn.ConvTranspose2d(ngf * mult, int(ngf * mult / 2),\n",
    "                                         kernel_size=3, stride=2,\n",
    "                                         padding=1, output_padding=1,\n",
    "                                         bias=use_bias),\n",
    "                      norm_layer(int(ngf * mult / 2)),\n",
    "                      nn.ReLU(True)]\n",
    "\n",
    "        up_all += [nn.ReflectionPad2d(3)]\n",
    "        up_all += [nn.Conv2d(ngf, output_nc, kernel_size=7, padding=0)]\n",
    "        up_all += [nn.Tanh()]\n",
    "\n",
    "        self.down_base = nn.Sequential(*down_base)\n",
    "        self.down_res = nn.Sequential(*down_res)\n",
    "        self.up_all = nn.Sequential(*up_all)\n",
    "\n",
    "    def forward(self, input, base_stage, temporal_stage, isTrain):\n",
    "        down_base = self.down_base(input)\n",
    "        down_res = self.down_res(input)\n",
    "        feature = base_stage * down_base + temporal_stage * down_res\n",
    "        return self.up_all(feature), feature\n",
    "\n",
    "\n",
    "# Define a resnet block\n",
    "class ResnetBlock(nn.Module):\n",
    "    def __init__(self, dim, padding_type, norm_layer, use_dropout, use_bias):\n",
    "        super(ResnetBlock, self).__init__()\n",
    "        self.conv_block = self.build_conv_block(dim, padding_type, norm_layer, use_dropout, use_bias)\n",
    "\n",
    "    def build_conv_block(self, dim, padding_type, norm_layer, use_dropout, use_bias):\n",
    "        conv_block = []\n",
    "        p = 0\n",
    "        if padding_type == 'reflect':\n",
    "            conv_block += [nn.ReflectionPad2d(1)]\n",
    "        elif padding_type == 'replicate':\n",
    "            conv_block += [nn.ReplicationPad2d(1)]\n",
    "        elif padding_type == 'zero':\n",
    "            p = 1\n",
    "        else:\n",
    "            raise NotImplementedError('padding [%s] is not implemented' % padding_type)\n",
    "\n",
    "        conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=p, bias=use_bias),\n",
    "                       norm_layer(dim),\n",
    "                       nn.ReLU(True)]\n",
    "        if use_dropout:\n",
    "            conv_block += [nn.Dropout(0.5)]\n",
    "\n",
    "        p = 0\n",
    "        if padding_type == 'reflect':\n",
    "            conv_block += [nn.ReflectionPad2d(1)]\n",
    "        elif padding_type == 'replicate':\n",
    "            conv_block += [nn.ReplicationPad2d(1)]\n",
    "        elif padding_type == 'zero':\n",
    "            p = 1\n",
    "        else:\n",
    "            raise NotImplementedError('padding [%s] is not implemented' % padding_type)\n",
    "        conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=p, bias=use_bias),\n",
    "                       norm_layer(dim)]\n",
    "\n",
    "        return nn.Sequential(*conv_block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x + self.conv_block(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnetGenerator(nn.Module):\n",
    "    def __init__(self, input_nc, output_nc, num_downs, ngf=64,\n",
    "                 norm_layer=nn.BatchNorm2d, use_dropout=False, gpu_ids=[]):\n",
    "        super(UnetGenerator, self).__init__()\n",
    "\n",
    "        # construct unet structure\n",
    "        unet_block = UnetSkipConnectionBlock(ngf * 8, ngf * 8, input_nc=None, submodule=None, norm_layer=norm_layer,\n",
    "                                             innermost=True, gpu_ids=gpu_ids)\n",
    "        for i in range(num_downs - 5):\n",
    "            unet_block = UnetSkipConnectionBlock(ngf * 8, ngf * 8, input_nc=None, submodule=unet_block,\n",
    "                                                 norm_layer=norm_layer, use_dropout=use_dropout, gpu_ids=gpu_ids)\n",
    "        unet_block = UnetSkipConnectionBlock(ngf * 4, ngf * 8, input_nc=None, submodule=unet_block,\n",
    "                                             norm_layer=norm_layer, gpu_ids=gpu_ids)\n",
    "        unet_block = UnetSkipConnectionBlock(ngf * 2, ngf * 4, input_nc=None, submodule=unet_block,\n",
    "                                             norm_layer=norm_layer, gpu_ids=gpu_ids)\n",
    "        unet_block = UnetSkipConnectionBlock(ngf, ngf * 2, input_nc=None, submodule=unet_block, norm_layer=norm_layer,\n",
    "                                             gpu_ids=gpu_ids)\n",
    "        unet_block = UnetSkipConnectionBlock(output_nc, ngf, input_nc=input_nc, submodule=unet_block, outermost=True,\n",
    "                                             norm_layer=norm_layer, gpu_ids=gpu_ids)\n",
    "\n",
    "        self.model = unet_block\n",
    "\n",
    "    def forward(self, input, base_stage, temporal_stage, isTrain):\n",
    "        return self.model(input, input, base_stage, temporal_stage, isTrain)\n",
    "\n",
    "class UnetSkipConnectionBlock(nn.Module):\n",
    "    def __init__(self, outer_nc, inner_nc, input_nc=None,\n",
    "                 submodule=None, outermost=False, innermost=False, norm_layer=nn.BatchNorm2d, use_dropout=False,\n",
    "                 gpu_ids=[]):\n",
    "        super(UnetSkipConnectionBlock, self).__init__()\n",
    "        self.device = torch.device('cuda:{}'.format(gpu_ids[0])) if gpu_ids else torch.device('cpu')\n",
    "        self.outermost = outermost\n",
    "        self.innermost = innermost\n",
    "        if type(norm_layer) == functools.partial:\n",
    "            use_bias = norm_layer.func == nn.InstanceNorm2d\n",
    "        else:\n",
    "            use_bias = norm_layer == nn.InstanceNorm2d\n",
    "        if input_nc is None:\n",
    "            input_nc = outer_nc\n",
    "        downconv_base = nn.Conv2d(input_nc, inner_nc, kernel_size=4,\n",
    "                                  stride=2, padding=1, bias=use_bias)\n",
    "        downrelu_base = nn.LeakyReLU(0.2, True)\n",
    "        downnorm_base = norm_layer(inner_nc)\n",
    "        downconv_res = nn.Conv2d(input_nc, inner_nc, kernel_size=4,\n",
    "                                 stride=2, padding=1, bias=use_bias)\n",
    "        downrelu_res = nn.LeakyReLU(0.2, True)\n",
    "        downnorm_res = norm_layer(inner_nc)\n",
    "        uprelu = nn.ReLU(True)\n",
    "        upnorm = norm_layer(outer_nc)\n",
    "\n",
    "        if outermost:\n",
    "            upconv = nn.ConvTranspose2d(inner_nc * 2, outer_nc,\n",
    "                                        kernel_size=4, stride=2,\n",
    "                                        padding=1)\n",
    "\n",
    "            down_base = [downconv_base]\n",
    "            down_res = [downconv_res]\n",
    "            up_all = [uprelu, upconv, nn.Tanh()]\n",
    "\n",
    "\n",
    "        elif innermost:\n",
    "            upconv = nn.ConvTranspose2d(inner_nc, outer_nc,\n",
    "                                        kernel_size=4, stride=2,\n",
    "                                        padding=1, bias=use_bias)\n",
    "\n",
    "            down_base = [downrelu_base, downconv_base]\n",
    "            down_res = [downrelu_res, downconv_res]\n",
    "            up_all = [uprelu, upconv, upnorm]\n",
    "\n",
    "        else:\n",
    "            upconv = nn.ConvTranspose2d(inner_nc * 2, outer_nc,\n",
    "                                        kernel_size=4, stride=2,\n",
    "                                        padding=1, bias=use_bias)\n",
    "\n",
    "            down_base = [downrelu_base, downconv_base, downnorm_base]\n",
    "            down_res = [downrelu_res, downconv_res, downnorm_res]\n",
    "            up = [uprelu, upconv, upnorm]\n",
    "            up_all = up + [nn.Dropout(0.5)] if use_dropout else up\n",
    "\n",
    "\n",
    "        self.down_base = nn.Sequential(*down_base)\n",
    "        self.down_res = nn.Sequential(*down_res)\n",
    "        self.up_all = nn.Sequential(*up_all)\n",
    "        self.sub = submodule\n",
    "\n",
    "\n",
    "    def forward(self, x_base, x_res, base_stage, temporal_stage, isTrain):\n",
    "        if self.outermost:\n",
    "            down_base = self.down_base(x_base)\n",
    "            down_res = self.down_res(x_res)\n",
    "            sub, feature = self.sub(down_base, down_res, base_stage, temporal_stage, isTrain)\n",
    "            sub_up = self.up_all(sub)\n",
    "            return sub_up, feature\n",
    "        if self.innermost:\n",
    "            concat_1 = base_stage * x_base + temporal_stage * x_res\n",
    "            if isTrain:\n",
    "                shape = x_base.shape\n",
    "                noise = torch.cuda.FloatTensor(shape) if torch.cuda.is_available() else torch.FloatTensor(shape)\n",
    "                torch.randn(shape, out=noise)\n",
    "                concat_1 += noise * 0.01\n",
    "            down_base = self.down_base(x_base)\n",
    "            down_res = self.down_res(x_res)\n",
    "\n",
    "            down = base_stage * down_base + temporal_stage * down_res\n",
    "            if isTrain:\n",
    "                shape = down_base.shape\n",
    "                noise = torch.cuda.FloatTensor(shape) if torch.cuda.is_available() else torch.FloatTensor(shape)\n",
    "                torch.randn(shape, out=noise)\n",
    "                down += noise * 0.01\n",
    "            sub_up = self.up_all(down)\n",
    "            return torch.cat([concat_1, sub_up], 1), down\n",
    "        else:\n",
    "            concat_1 = base_stage * x_base + temporal_stage * x_res\n",
    "            if isTrain:\n",
    "                shape = x_base.shape\n",
    "                noise = torch.cuda.FloatTensor(shape) if torch.cuda.is_available() else torch.FloatTensor(shape)\n",
    "                torch.randn(shape, out=noise)\n",
    "                concat_1 += noise * 0.01\n",
    "            down_base = self.down_base(x_base)\n",
    "            down_res = self.down_res(x_res)\n",
    "            sub, feature = self.sub(down_base, down_res, base_stage, temporal_stage, isTrain)\n",
    "            sub_up = self.up_all(sub)\n",
    "            return torch.cat([concat_1, sub_up], 1), feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLayerDiscriminator(nn.Module):\n",
    "    def __init__(self, input_nc, ndf=64, n_layers=3, norm_layer=nn.BatchNorm2d, use_sigmoid=False):\n",
    "        super(NLayerDiscriminator, self).__init__()\n",
    "        if type(norm_layer) == functools.partial:\n",
    "            use_bias = norm_layer.func == nn.InstanceNorm2d\n",
    "        else:\n",
    "            use_bias = norm_layer == nn.InstanceNorm2d\n",
    "\n",
    "        kw = 4\n",
    "        padw = 1\n",
    "        sequence = [\n",
    "            nn.Conv2d(input_nc, ndf, kernel_size=kw, stride=2, padding=padw),\n",
    "            nn.LeakyReLU(0.2, True)\n",
    "        ]\n",
    "\n",
    "        nf_mult = 1\n",
    "        nf_mult_prev = 1\n",
    "        for n in range(1, n_layers):\n",
    "            nf_mult_prev = nf_mult\n",
    "            nf_mult = min(2 ** n, 8)\n",
    "            sequence += [\n",
    "                nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult,\n",
    "                          kernel_size=kw, stride=2, padding=padw, bias=use_bias),\n",
    "                norm_layer(ndf * nf_mult),\n",
    "                nn.LeakyReLU(0.2, True)\n",
    "            ]\n",
    "\n",
    "        nf_mult_prev = nf_mult\n",
    "        nf_mult = min(2 ** n_layers, 8)\n",
    "        sequence += [\n",
    "            nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult,\n",
    "                      kernel_size=kw, stride=1, padding=padw, bias=use_bias),\n",
    "            norm_layer(ndf * nf_mult),\n",
    "            nn.LeakyReLU(0.2, True)\n",
    "        ]\n",
    "\n",
    "        sequence += [nn.Conv2d(ndf * nf_mult, 1, kernel_size=kw, stride=1, padding=padw)]\n",
    "\n",
    "        if use_sigmoid:\n",
    "            sequence += [nn.Sigmoid()]\n",
    "\n",
    "        self.model = nn.Sequential(*sequence)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PixelDiscriminator(nn.Module):\n",
    "    def __init__(self, input_nc, ndf=64, norm_layer=nn.BatchNorm2d, use_sigmoid=False):\n",
    "        super(PixelDiscriminator, self).__init__()\n",
    "        if type(norm_layer) == functools.partial:\n",
    "            use_bias = norm_layer.func == nn.InstanceNorm2d\n",
    "        else:\n",
    "            use_bias = norm_layer == nn.InstanceNorm2d\n",
    "\n",
    "        self.net = [\n",
    "            nn.Conv2d(input_nc, ndf, kernel_size=1, stride=1, padding=0),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            nn.Conv2d(ndf, ndf * 2, kernel_size=1, stride=1, padding=0, bias=use_bias),\n",
    "            norm_layer(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            nn.Conv2d(ndf * 2, 1, kernel_size=1, stride=1, padding=0, bias=use_bias)]\n",
    "\n",
    "        if use_sigmoid:\n",
    "            self.net.append(nn.Sigmoid())\n",
    "\n",
    "        self.net = nn.Sequential(*self.net)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.net(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlphaDiscriminator(nn.Module):\n",
    "    def __init__(self, input_nc, norm_layer=nn.BatchNorm2d, use_sigmoid=False):\n",
    "        super(AlphaDiscriminator, self).__init__()\n",
    "        if type(norm_layer) == functools.partial:\n",
    "            use_bias = norm_layer.func == nn.InstanceNorm2d\n",
    "        else:\n",
    "            use_bias = norm_layer == nn.InstanceNorm2d\n",
    "\n",
    "        # self.net = [\n",
    "        #     nn.Linear(input_nc, 256, bias=True),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Linear(256, 256, bias=True),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Linear(256, 1, bias=True)]\n",
    "        self.net = [\n",
    "            nn.Linear(input_nc, input_nc, bias=True),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            nn.Linear(input_nc, input_nc, bias=True),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            nn.Linear(input_nc, 1, bias=True)\n",
    "        ]\n",
    "\n",
    "        if use_sigmoid:\n",
    "            self.net.append(nn.Sigmoid())\n",
    "\n",
    "        self.net = nn.Sequential(*self.net)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.net(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_norm_layer(norm_type='instance'):\n",
    "    if norm_type == 'batch':\n",
    "        norm_layer = functools.partial(nn.BatchNorm2d, affine=True)\n",
    "    elif norm_type == 'instance':\n",
    "        norm_layer = functools.partial(nn.InstanceNorm2d, affine=False, track_running_stats=False)\n",
    "    elif norm_type == 'group':\n",
    "        norm_layer = functools.partial(nn.GroupNorm, num_groups=64)\n",
    "    elif norm_type == 'none':\n",
    "        norm_layer = None\n",
    "    else:\n",
    "        raise NotImplementedError('normalization layer [%s] is not found' % norm_type)\n",
    "    return norm_layer\n",
    "\n",
    "\n",
    "def init_weights(net, init_type='normal', gain=0.02):\n",
    "    def init_func(m):\n",
    "        classname = m.__class__.__name__\n",
    "        if hasattr(m, 'weight') and (classname.find('Conv') != -1 or classname.find('Linear') != -1):\n",
    "            if init_type == 'normal':\n",
    "                init.normal_(m.weight.data, 0.0, gain)\n",
    "            elif init_type == 'xavier':\n",
    "                init.xavier_normal_(m.weight.data, gain=gain)\n",
    "            elif init_type == 'kaiming':\n",
    "                init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
    "            elif init_type == 'orthogonal':\n",
    "                init.orthogonal_(m.weight.data, gain=gain)\n",
    "            else:\n",
    "                raise NotImplementedError('initialization method [%s] is not implemented' % init_type)\n",
    "            if hasattr(m, 'bias') and m.bias is not None:\n",
    "                init.constant_(m.bias.data, 0.0)\n",
    "        elif classname.find('BatchNorm2d') != -1:\n",
    "            init.normal_(m.weight.data, 1.0, gain)\n",
    "            init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "    print('initialize network with %s' % init_type)\n",
    "    net.apply(init_func)\n",
    "    \n",
    "def init_net(net, init_type='normal', init_gain=0.02, gpu_ids=[]):\n",
    "    if len(gpu_ids) > 0:\n",
    "        assert (torch.cuda.is_available())\n",
    "        net.to(gpu_ids[0])\n",
    "        net = torch.nn.DataParallel(net, gpu_ids)\n",
    "    init_weights(net, init_type, gain=init_gain)\n",
    "    return net\n",
    "\n",
    "\n",
    "def get_scheduler(optimizer, opt):\n",
    "    if opt.lr_policy == 'lambda':\n",
    "        def lambda_rule(epoch):\n",
    "            lr_l = 1.0 - max(0, epoch + 1 + opt.epoch_count - opt.niter) / float(opt.niter_decay + 1)\n",
    "            return lr_l\n",
    "\n",
    "        scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda_rule)\n",
    "    elif opt.lr_policy == 'step':\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, step_size=opt.lr_decay_iters, gamma=0.1)\n",
    "    elif opt.lr_policy == 'plateau':\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.2, threshold=0.01, patience=5)\n",
    "    elif opt.lr_policy == 'cosine':\n",
    "        scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=opt.niter, eta_min=0)\n",
    "    else:\n",
    "        return NotImplementedError('learning rate policy [%s] is not implemented', opt.lr_policy)\n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_G(input_nc, output_nc, ngf, netG, norm='batch', use_dropout=False, init_type='normal', init_gain=0.02,\n",
    "             gpu_ids=[]):\n",
    "    net = None\n",
    "    norm_layer = get_norm_layer(norm_type=norm)\n",
    "\n",
    "    if netG == 'resnet_9blocks':\n",
    "        net = ResnetGenerator(input_nc, output_nc, ngf, norm_layer=norm_layer, use_dropout=use_dropout, n_blocks=9)\n",
    "    elif netG == 'resnet_6blocks':\n",
    "        net = ResnetGenerator(input_nc, output_nc, ngf, norm_layer=norm_layer, use_dropout=use_dropout, n_blocks=6)\n",
    "    elif netG == 'unet_64':\n",
    "        net = UnetGenerator(input_nc, output_nc, 6, ngf, norm_layer=norm_layer, use_dropout=use_dropout,\n",
    "                            gpu_ids=gpu_ids)\n",
    "    elif netG == 'unet_128':\n",
    "        net = UnetGenerator(input_nc, output_nc, 7, ngf, norm_layer=norm_layer, use_dropout=use_dropout, gpu_ids=gpu_ids)\n",
    "    elif netG == 'unet_256':\n",
    "        net = UnetGenerator(input_nc, output_nc, 8, ngf, norm_layer=norm_layer, use_dropout=use_dropout, gpu_ids=gpu_ids)\n",
    "    else:\n",
    "        raise NotImplementedError('Generator model name [%s] is not recognized' % netG)\n",
    "    return init_net(net, init_type, init_gain, gpu_ids)\n",
    "\n",
    "\n",
    "def define_D(input_nc, ndf, netD,\n",
    "             n_layers_D=3, norm='batch', use_sigmoid=False, init_type='normal', init_gain=0.02, gpu_ids=[]):\n",
    "    net = None\n",
    "    norm_layer = get_norm_layer(norm_type=norm)\n",
    "\n",
    "    if netD == 'basic':\n",
    "        net = NLayerDiscriminator(input_nc, ndf, n_layers=3, norm_layer=norm_layer, use_sigmoid=use_sigmoid)\n",
    "    elif netD == 'n_layers':\n",
    "        net = NLayerDiscriminator(input_nc, ndf, n_layers_D, norm_layer=norm_layer, use_sigmoid=use_sigmoid)\n",
    "    elif netD == 'pixel':\n",
    "        net = PixelDiscriminator(input_nc, ndf, norm_layer=norm_layer, use_sigmoid=use_sigmoid)\n",
    "    else:\n",
    "        raise NotImplementedError('Discriminator model name [%s] is not recognized' % net)\n",
    "    return init_net(net, init_type, init_gain, gpu_ids)\n",
    "\n",
    "\n",
    "def define_D_alpha(input_nc, norm='batch', use_sigmoid=False, init_type='normal', init_gain=0.02, gpu_ids=[]):\n",
    "    norm_layer = get_norm_layer(norm_type=norm)\n",
    "    net = AlphaDiscriminator(input_nc, norm_layer=norm_layer, use_sigmoid=use_sigmoid)\n",
    "    return init_net(net, init_type, init_gain, gpu_ids)\n",
    "\n",
    "def print_network(net):\n",
    "    num_params = 0\n",
    "    for param in net.parameters():\n",
    "        num_params += param.numel()\n",
    "    print(net)\n",
    "    print('Total number of parameters: %d' % num_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel():\n",
    "\n",
    "    # modify parser to add command line options,\n",
    "    # and also change the default values if needed\n",
    "    @staticmethod\n",
    "    def modify_commandline_options(parser, is_train):\n",
    "        return parser\n",
    "\n",
    "    def name(self):\n",
    "        return 'BaseModel'\n",
    "\n",
    "    def test_all_frame(self):\n",
    "        pass\n",
    "\n",
    "    def initialize(self, opt):\n",
    "        self.opt = opt\n",
    "        self.gpu_ids = opt.gpu_ids\n",
    "        self.isTrain = opt.isTrain\n",
    "        self.device = torch.device('cuda:{}'.format(self.gpu_ids[0])) if self.gpu_ids else torch.device('cpu')\n",
    "        self.save_dir = os.path.join(opt.checkpoints_dir, opt.name)\n",
    "        if opt.resize_or_crop != 'scale_width':\n",
    "            torch.backends.cudnn.benchmark = True\n",
    "        self.loss_names = []\n",
    "        self.model_names = []\n",
    "        self.visual_names = []\n",
    "        self.image_paths = []\n",
    "        self.optimizers = []\n",
    "\n",
    "    def set_input(self, input):\n",
    "        self.input = input\n",
    "\n",
    "    def forward(self):\n",
    "        pass\n",
    "\n",
    "    # load and print networks; create schedulers\n",
    "    def setup(self, opt, parser=None):\n",
    "        if self.isTrain:\n",
    "            self.schedulers = [get_scheduler(optimizer, opt) for optimizer in self.optimizers]\n",
    "\n",
    "        if not self.isTrain or opt.continue_train:\n",
    "            self.load_networks(opt.epoch)\n",
    "        self.print_networks(opt.verbose)\n",
    "\n",
    "    # make models eval mode during test time\n",
    "    def eval(self):\n",
    "        for name in self.model_names:\n",
    "            if isinstance(name, str):\n",
    "                net = getattr(self, 'net' + name)\n",
    "                net.eval()\n",
    "\n",
    "    def train(self):\n",
    "        for name in self.model_names:\n",
    "            if isinstance(name, str):\n",
    "                net = getattr(self, 'net' + name)\n",
    "                net.train()\n",
    "\n",
    "    # used in test time, wrapping `forward` in no_grad() so we don't save\n",
    "    # intermediate steps for backprop\n",
    "    def test(self):\n",
    "        with torch.no_grad():\n",
    "            self.forward()\n",
    "\n",
    "    # get image paths\n",
    "    def get_image_paths(self):\n",
    "        return self.image_paths\n",
    "\n",
    "    def optimize_parameters(self):\n",
    "        pass\n",
    "\n",
    "    # update learning rate (called once every epoch)\n",
    "    def update_learning_rate(self):\n",
    "        for scheduler in self.schedulers:\n",
    "            scheduler.step()\n",
    "        lr = self.optimizers[0].param_groups[0]['lr']\n",
    "        # print('learning rate = %.7f' % lr)\n",
    "\n",
    "    # return visualization images. train.py will display these images, and save the images to a html\n",
    "    def get_current_visuals(self):\n",
    "        visual_ret = OrderedDict()\n",
    "        for name in self.visual_names:\n",
    "            if isinstance(name, str):\n",
    "                attr = getattr(self, name)\n",
    "                if isinstance(attr, list):\n",
    "                    for i in range(len(attr)):\n",
    "                        visual_ret[name+str(i)] = attr[i]\n",
    "                else:\n",
    "                    visual_ret[name] = attr\n",
    "\n",
    "        return visual_ret\n",
    "\n",
    "    # return traning losses/errors. train.py will print out these errors as debugging information\n",
    "    def get_current_losses(self):\n",
    "        errors_ret = OrderedDict()\n",
    "        for name in self.loss_names:\n",
    "            if isinstance(name, str):\n",
    "                # float(...) works for both scalar tensor and float number\n",
    "                a = getattr(self, 'loss_' + name)\n",
    "                if isinstance(a, list):\n",
    "                    errors_ret[name] = a\n",
    "                else:\n",
    "                    errors_ret[name] = float(a)\n",
    "        return errors_ret\n",
    "\n",
    "    # save models to the disk\n",
    "    # def save_networks(self, epoch):\n",
    "    #     for name in self.model_names:\n",
    "    #         if isinstance(name, str):\n",
    "    #             save_filename = '%s_net_%s.pth' % (epoch, name)\n",
    "    #             save_path = os.path.join(self.save_dir, save_filename)\n",
    "    #             net = getattr(self, 'net' + name)\n",
    "\n",
    "    #             if len(self.gpu_ids) > 0 and torch.cuda.is_available():\n",
    "    #                 torch.save(net.module.cpu().state_dict(), save_path)\n",
    "    #                 net.cuda(self.gpu_ids[0])\n",
    "    #             else:\n",
    "    #                 torch.save(net.cpu().state_dict(), save_path)\n",
    "\n",
    "    def save_networks(self, epoch):\n",
    "        for name in self.model_names:\n",
    "            if isinstance(name, str):\n",
    "                save_filename = '%s_net_%s.pth' % (epoch, name)\n",
    "                save_path = os.path.join(self.save_dir, save_filename)\n",
    "                net = getattr(self, 'net' + name)\n",
    "\n",
    "                if len(self.gpu_ids) > 0 and torch.cuda.is_available():\n",
    "                    if isinstance(net, torch.nn.DataParallel):\n",
    "                        torch.save(net.module.cpu().state_dict(), save_path)\n",
    "                    else:\n",
    "                        torch.save(net.cpu().state_dict(), save_path)\n",
    "                    net.cuda(self.gpu_ids[0])\n",
    "                else:\n",
    "                    torch.save(net.cpu().state_dict(), save_path)\n",
    "\n",
    "\n",
    "    def __patch_instance_norm_state_dict(self, state_dict, module, keys, i=0):\n",
    "        key = keys[i]\n",
    "        if i + 1 == len(keys):  # at the end, pointing to a parameter/buffer\n",
    "            if module.__class__.__name__.startswith('InstanceNorm') and \\\n",
    "                    (key == 'running_mean' or key == 'running_var'):\n",
    "                if getattr(module, key) is None:\n",
    "                    state_dict.pop('.'.join(keys))\n",
    "            if module.__class__.__name__.startswith('InstanceNorm') and \\\n",
    "               (key == 'num_batches_tracked'):\n",
    "                state_dict.pop('.'.join(keys))\n",
    "        else:\n",
    "            self.__patch_instance_norm_state_dict(state_dict, getattr(module, key), keys, i + 1)\n",
    "\n",
    "    # load models from the disk\n",
    "    def load_networks(self, epoch):\n",
    "        for name in self.model_names:\n",
    "            if isinstance(name, str):\n",
    "                load_filename = '%s_net_%s.pth' % (epoch, name)\n",
    "                load_path = os.path.join(self.save_dir, load_filename)\n",
    "                net = getattr(self, 'net' + name)\n",
    "                if isinstance(net, torch.nn.DataParallel):\n",
    "                    net = net.module\n",
    "                print('loading the model from %s' % load_path)\n",
    "                # if you are using PyTorch newer than 0.4 (e.g., built from\n",
    "                # GitHub source), you can remove str() on self.device\n",
    "                state_dict = torch.load(load_path, map_location=str(self.device))\n",
    "                if hasattr(state_dict, '_metadata'):\n",
    "                    del state_dict._metadata\n",
    "\n",
    "                # patch InstanceNorm checkpoints prior to 0.4\n",
    "                for key in list(state_dict.keys()):  # need to copy keys here because we mutate in loop\n",
    "                    self.__patch_instance_norm_state_dict(state_dict, net, key.split('.'))\n",
    "                net.load_state_dict(state_dict)\n",
    "\n",
    "    # print network information\n",
    "    def print_networks(self, verbose):\n",
    "        print('---------- Networks initialized -------------')\n",
    "        for name in self.model_names:\n",
    "            if isinstance(name, str):\n",
    "                net = getattr(self, 'net' + name)\n",
    "                num_params = 0\n",
    "                for param in net.parameters():\n",
    "                    num_params += param.numel()\n",
    "                if verbose:\n",
    "                    print(net)\n",
    "                print('[Network %s] Total number of parameters : %.3f M' % (name, num_params / 1e6))\n",
    "        print('-----------------------------------------------')\n",
    "\n",
    "    # set requies_grad=Fasle to avoid computation\n",
    "    def set_requires_grad(self, nets, requires_grad=False):\n",
    "        if not isinstance(nets, list):\n",
    "            nets = [nets]\n",
    "        for net in nets:\n",
    "            if net is not None:\n",
    "                for param in net.parameters():\n",
    "                    param.requires_grad = requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AffineGANModel(BaseModel):\n",
    "    def name(self):\n",
    "        return \"AffineGANModel\"\n",
    "\n",
    "    @staticmethod\n",
    "    def modify_commandline_options(parser, is_train=True):\n",
    "        # AffineGAN use instance norm\n",
    "        parser.set_defaults(pool_size=0, no_lsgan=False, norm=\"instance\")\n",
    "        parser.set_defaults(dataset_mode=\"affineGAN\")\n",
    "        parser.set_defaults(netG=\"unet_256\")\n",
    "        if is_train:\n",
    "            parser.add_argument(\n",
    "                \"--lambda_L1\", type=float, default=100.0, help=\"weight for L1 loss\"\n",
    "            )\n",
    "\n",
    "        return parser\n",
    "\n",
    "    def initialize(self, opt):\n",
    "        BaseModel.initialize(self, opt)\n",
    "        self.isTrain = opt.isTrain\n",
    "        # specify the training losses you want to print out. The program will call base_model.get_current_losses\n",
    "        self.loss_names = [\n",
    "            \"G_GAN_D1\",\n",
    "            \"G_L1\",\n",
    "            \"D_real\",\n",
    "            \"D_fake\",\n",
    "            \"G_GAN_D_alpha\",\n",
    "            \"D_alpha\",\n",
    "            \"img_recons\",\n",
    "        ]\n",
    "        if not opt.no_patch:\n",
    "            self.loss_names += [\n",
    "                \"G_GAN_patch\",\n",
    "                \"D_real_patch\",\n",
    "                \"D_fake_patch\",\n",
    "                \"D_patch\",\n",
    "            ]\n",
    "\n",
    "        if self.isTrain:\n",
    "            self.visual_names = [\"input_A\", \"fake_B\", \"real_B\"]\n",
    "            self.model_names = [\"G\", \"D\", \"D_alpha\"]\n",
    "            if not opt.no_patch:\n",
    "                self.model_names.append(\"D_Patch\")\n",
    "\n",
    "        else:  # during test time, only load Gs\n",
    "            self.visual_names = [\"input_A\"] + [\"fake_B_list\"]\n",
    "            self.model_names = [\"G\"]\n",
    "        # load/define networks\n",
    "        self.netG = define_G(\n",
    "            opt.input_nc,\n",
    "            opt.input_nc,\n",
    "            opt.ngf,\n",
    "            opt.netG,\n",
    "            opt.norm,\n",
    "            not opt.no_dropout,\n",
    "            opt.init_type,\n",
    "            opt.init_gain,\n",
    "            self.gpu_ids,\n",
    "        )\n",
    "\n",
    "        if self.isTrain:\n",
    "            use_sigmoid = opt.no_lsgan\n",
    "            self.netD = define_D(\n",
    "                opt.input_nc + opt.output_nc,\n",
    "                opt.ndf,\n",
    "                opt.netD,\n",
    "                opt.n_layers_D,\n",
    "                opt.norm,\n",
    "                use_sigmoid,\n",
    "                opt.init_type,\n",
    "                opt.init_gain,\n",
    "                self.gpu_ids,\n",
    "            )\n",
    "            self.netD_alpha = define_D_alpha(\n",
    "                opt.train_imagenum,\n",
    "                opt.norm,\n",
    "                use_sigmoid,\n",
    "                opt.init_type,\n",
    "                opt.init_gain,\n",
    "                self.gpu_ids,\n",
    "            )\n",
    "\n",
    "            # define loss functions\n",
    "            self.criterionGAN = GANLoss(use_lsgan=not opt.no_lsgan).to(\n",
    "                self.device\n",
    "            )\n",
    "            self.criterionL1 = torch.nn.L1Loss()\n",
    "\n",
    "            # initialize optimizers\n",
    "            self.optimizers = []\n",
    "            self.optimizer_G = torch.optim.Adam(\n",
    "                self.netG.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999)\n",
    "            )\n",
    "            self.optimizer_D = torch.optim.Adam(\n",
    "                self.netD.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999)\n",
    "            )\n",
    "            self.optimizer_D_Alpha = torch.optim.Adam(\n",
    "                self.netD_alpha.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999)\n",
    "            )\n",
    "\n",
    "            self.optimizers.append(self.optimizer_G)\n",
    "            self.optimizers.append(self.optimizer_D)\n",
    "            self.optimizers.append(self.optimizer_D_Alpha)\n",
    "\n",
    "            if not opt.no_patch:\n",
    "                self.netD_Patch = define_D(\n",
    "                    opt.input_nc + opt.output_nc,\n",
    "                    opt.ndf,\n",
    "                    opt.netD,\n",
    "                    opt.n_layers_D,\n",
    "                    opt.norm,\n",
    "                    use_sigmoid,\n",
    "                    opt.init_type,\n",
    "                    opt.init_gain,\n",
    "                    self.gpu_ids,\n",
    "                )\n",
    "                self.optimizer_D_Patch = torch.optim.Adam(\n",
    "                    self.netD_Patch.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999)\n",
    "                )\n",
    "                self.optimizers.append(self.optimizer_D_Patch)\n",
    "\n",
    "    def get_alpha(self, f_t0, f_t, f_t0_res):\n",
    "        return torch.abs(torch.sum((f_t - f_t0) * f_t0_res)) / (\n",
    "            f_t0_res.norm() + 1e-6\n",
    "        )\n",
    "\n",
    "    def set_input(self, input):\n",
    "        self.input_A = input[\"A\"].to(self.device)\n",
    "        self.image_paths = input[\"A_paths\"]\n",
    "        if self.isTrain:\n",
    "            self.input_B_list = []\n",
    "            self.input_B_patch_list = []\n",
    "            for img_idx in range(self.opt.train_imagenum):\n",
    "                self.input_B_list.append(input[\"B_list\"][img_idx].to(self.device))\n",
    "                if not self.opt.no_patch:\n",
    "                    self.input_A_patch = input[\"A_patch\"].to(self.device)\n",
    "                    self.input_B_patch_list.append(\n",
    "                        input[\"B_patch_list\"][img_idx].to(self.device)\n",
    "                    )\n",
    "\n",
    "    def forward(self):\n",
    "        if not self.opt.no_patch and self.isTrain:\n",
    "            self.input_A_img_patch = self.input_A * self.input_A_patch\n",
    "\n",
    "        self.t0_reconstruct, f_t0 = self.netG(self.input_A, 1.0, 0.0, self.isTrain)\n",
    "\n",
    "        self.real_B_list = []\n",
    "        self.fake_B_list = []\n",
    "        self.B_reconstruct_img_list = []\n",
    "        if not self.opt.no_patch:\n",
    "            self.fake_B_img_patch_list = []\n",
    "            self.real_B_img_patch_list = []\n",
    "\n",
    "        alpha_list_torch = []\n",
    "\n",
    "        _, f_t0_res = self.netG(self.input_A, 0.0, 1.0, self.isTrain)\n",
    "        f_t0_res = torch.squeeze(f_t0_res)\n",
    "        f_t0 = torch.squeeze(f_t0)\n",
    "\n",
    "        for img_idx in range(self.opt.train_imagenum):\n",
    "            real_B = self.input_B_list[img_idx]\n",
    "\n",
    "            t_reconstruct, f_t = self.netG(real_B, 1.0, 0.0, self.isTrain)\n",
    "            self.B_reconstruct_img_list.append(t_reconstruct)\n",
    "            f_t = torch.squeeze(f_t)\n",
    "            alpha = self.get_alpha(f_t0, f_t, f_t0_res)\n",
    "            alpha_list_torch.append(alpha.view(1))\n",
    "\n",
    "            fake_B, _ = self.netG(self.input_A, 1.0, float(alpha), self.isTrain)\n",
    "\n",
    "            self.real_B_list.append(real_B)\n",
    "            self.fake_B_list.append(fake_B)\n",
    "\n",
    "            if not self.opt.no_patch:\n",
    "                real_B_patch = self.input_B_patch_list[img_idx]\n",
    "                real_B_img_patch = real_B * real_B_patch\n",
    "                fake_B_img_patch = fake_B * real_B_patch\n",
    "                self.fake_B_img_patch_list.append(fake_B_img_patch)\n",
    "                self.real_B_img_patch_list.append(real_B_img_patch)\n",
    "\n",
    "        self.alpha_list_torch = torch.stack(alpha_list_torch, dim=1)\n",
    "\n",
    "        self.alpha_list_sample = torch.rand(1, self.opt.train_imagenum).to(self.device)\n",
    "\n",
    "        self.fake_B = self.fake_B_list[0]\n",
    "        self.real_B = self.real_B_list[0]\n",
    "\n",
    "    def backward_D(self):\n",
    "        # Fake\n",
    "        # stop backprop to the generator by detaching fake_B\n",
    "        loss_D = 0\n",
    "        for img_idx in range(self.opt.train_imagenum):\n",
    "            fake_AB = torch.cat((self.input_A, self.fake_B_list[img_idx]), 1)\n",
    "            pred_fake = self.netD(fake_AB.detach())\n",
    "            self.loss_D_fake = self.criterionGAN(pred_fake, False)\n",
    "\n",
    "            # Real\n",
    "            real_AB = torch.cat((self.input_A, self.real_B_list[img_idx]), 1)\n",
    "            pred_real = self.netD(real_AB.detach())\n",
    "            self.loss_D_real = self.criterionGAN(pred_real, True)\n",
    "\n",
    "            # Combined loss\n",
    "            loss_D += (self.loss_D_fake + self.loss_D_real) * 0.5\n",
    "\n",
    "        self.loss_D = loss_D / (self.opt.train_imagenum + 0.0)\n",
    "        self.loss_D.backward()\n",
    "\n",
    "    def backward_D_patch(self):\n",
    "        # Fake\n",
    "        # stop backprop to the generator by detaching fake_B\n",
    "        loss_D_patch = 0\n",
    "        for img_idx in range(self.opt.train_imagenum):\n",
    "            fake_AB_patch = torch.cat(\n",
    "                (self.input_A_img_patch, self.fake_B_img_patch_list[img_idx]), 1\n",
    "            )\n",
    "            pred_fake_patch = self.netD_Patch(fake_AB_patch.detach())\n",
    "            self.loss_D_fake_patch = self.criterionGAN(pred_fake_patch, False)\n",
    "\n",
    "            # Real\n",
    "            real_AB_patch = torch.cat(\n",
    "                (self.input_A_img_patch, self.real_B_img_patch_list[img_idx]), 1\n",
    "            )\n",
    "            pred_real_patch = self.netD_Patch(real_AB_patch.detach())\n",
    "            self.loss_D_real_patch = self.criterionGAN(pred_real_patch, True)\n",
    "\n",
    "            # Combined loss\n",
    "            loss_D_patch += (self.loss_D_fake_patch + self.loss_D_real_patch) * 0.5\n",
    "        self.loss_D_patch = loss_D_patch / (self.opt.train_imagenum + 0.0)\n",
    "        self.loss_D_patch.backward()\n",
    "\n",
    "    def backward_D_alpha(self):\n",
    "        # Fake\n",
    "        # stop backprop to the generator by detaching fake_B\n",
    "\n",
    "        pred_fake_alpha = self.netD_alpha(self.alpha_list_torch.detach())\n",
    "        pred_true_alpha = self.netD_alpha(self.alpha_list_sample.detach())\n",
    "\n",
    "        self.loss_D_fake_alpha = self.criterionGAN(pred_fake_alpha, False)\n",
    "        self.loss_D_real_alpha = self.criterionGAN(pred_true_alpha, True)\n",
    "        # Combined loss\n",
    "        self.loss_D_alpha = (\n",
    "            (self.loss_D_fake_alpha + self.loss_D_real_alpha) * 0.5 * self.opt.lambda_A\n",
    "        )\n",
    "        self.loss_D_alpha.backward()\n",
    "\n",
    "    def backward_G(self):\n",
    "        # First, G(A) should fake the discriminator\n",
    "        loss_G = 0\n",
    "        loss_G_GAN_D1 = 0\n",
    "        loss_G_GAN_patch = 0\n",
    "        loss_G_L1 = 0\n",
    "        img_recons_loss = 0\n",
    "\n",
    "        pred_fake_alpha = self.netD_alpha(self.alpha_list_torch)\n",
    "        loss_G_GAN_D_alpha = (\n",
    "            self.criterionGAN(pred_fake_alpha, True) * self.opt.lambda_A\n",
    "        )\n",
    "\n",
    "        for img_idx in range(self.opt.train_imagenum):\n",
    "            fake_AB = torch.cat((self.input_A, self.fake_B_list[img_idx]), 1)\n",
    "            pred_fake = self.netD(fake_AB)\n",
    "            current_loss_G_GAN_D1 = self.criterionGAN(pred_fake, True)\n",
    "            loss_G_GAN_D1 += current_loss_G_GAN_D1 / (self.opt.train_imagenum + 0.0)\n",
    "\n",
    "            # First_2, G(A) should fake the discriminator_patch\n",
    "            if not self.opt.no_patch:\n",
    "                fake_AB_patch = torch.cat(\n",
    "                    (self.input_A_img_patch, self.fake_B_img_patch_list[img_idx]), 1\n",
    "                )\n",
    "                pred_fake_patch = self.netD_Patch(fake_AB_patch)\n",
    "                current_loss_G_GAN_patch = self.criterionGAN(pred_fake_patch, True)\n",
    "                loss_G_GAN_patch += current_loss_G_GAN_patch / (\n",
    "                    self.opt.train_imagenum + 0.0\n",
    "                )\n",
    "                loss_G += current_loss_G_GAN_patch\n",
    "\n",
    "            # Second, G(A) = B\n",
    "            current_loss_G_L1 = (\n",
    "                self.criterionL1(self.fake_B_list[img_idx], self.real_B_list[img_idx])\n",
    "                * self.opt.lambda_L1\n",
    "            )\n",
    "            loss_G_L1 += current_loss_G_L1 / (self.opt.train_imagenum + 0.0)\n",
    "            current_img_recons_loss = (\n",
    "                self.criterionL1(\n",
    "                    self.B_reconstruct_img_list[img_idx], self.real_B_list[img_idx]\n",
    "                )\n",
    "                * 10.0\n",
    "            )\n",
    "            img_recons_loss = current_img_recons_loss / (self.opt.train_imagenum + 0.0)\n",
    "            loss_G += (\n",
    "                current_loss_G_GAN_D1 + current_loss_G_L1 + current_img_recons_loss\n",
    "            )\n",
    "\n",
    "        loss_G += loss_G_GAN_D_alpha\n",
    "        loss_G /= self.opt.train_imagenum + 0.0\n",
    "        self.loss_G = loss_G\n",
    "        self.loss_G_GAN_D1 = loss_G_GAN_D1\n",
    "        self.loss_G_GAN_patch = loss_G_GAN_patch\n",
    "        self.loss_G_L1 = loss_G_L1\n",
    "        self.loss_G_GAN_D_alpha = loss_G_GAN_D_alpha\n",
    "        self.loss_img_recons = img_recons_loss\n",
    "        self.loss_G.backward()\n",
    "\n",
    "    def optimize_parameters(self):\n",
    "        self.forward()\n",
    "\n",
    "        self.set_requires_grad(self.netD_alpha, True)\n",
    "        self.optimizer_D_Alpha.zero_grad()\n",
    "        self.backward_D_alpha()\n",
    "        self.optimizer_D_Alpha.step()\n",
    "\n",
    "        self.set_requires_grad(self.netD, True)\n",
    "        self.optimizer_D.zero_grad()\n",
    "        self.backward_D()\n",
    "        self.optimizer_D.step()\n",
    "\n",
    "        if not self.opt.no_patch:\n",
    "            self.set_requires_grad(self.netD_Patch, True)\n",
    "            self.optimizer_D_Patch.zero_grad()\n",
    "            self.backward_D_patch()\n",
    "            self.optimizer_D_Patch.step()\n",
    "            self.set_requires_grad(self.netD_Patch, False)\n",
    "\n",
    "        self.set_requires_grad(self.netD, False)\n",
    "        self.set_requires_grad(self.netD_alpha, False)\n",
    "\n",
    "        self.optimizer_G.zero_grad()\n",
    "        self.backward_G()\n",
    "        self.optimizer_G.step()\n",
    "\n",
    "    # no backprop gradients\n",
    "    def test(self):\n",
    "        with torch.no_grad():\n",
    "            self.fake_B_list = []\n",
    "            for i in range(int(1.0 / self.opt.interval)):\n",
    "                self.fake_B_list.append(\n",
    "                    self.netG(self.input_A, 1.0, self.opt.interval * i, self.isTrain)[0]\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_model_using_name(model_name):\n",
    "    model = None\n",
    "    if model_name.lower() == \"affinegan\":\n",
    "        model = AffineGANModel\n",
    "\n",
    "    if model is None:\n",
    "        print(\n",
    "            \"There should be a subclass of BaseModel with class name that matches %s in lowercase.\"\n",
    "            % model_name\n",
    "        )\n",
    "        exit(0)\n",
    "\n",
    "    return model\n",
    "\n",
    "def get_option_setter(model_name):\n",
    "    model_class = find_model_using_name(model_name)\n",
    "    return model_class.modify_commandline_options\n",
    "\n",
    "\n",
    "def create_model(opt):\n",
    "    model = find_model_using_name(opt.model)\n",
    "    instance = model()\n",
    "    instance.initialize(opt)\n",
    "    print(\"model [%s] was created\" % (instance.name()))\n",
    "    return instance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Params:\n",
    "    def __init__(self):\n",
    "        self.initialized = False\n",
    "        self.isTrain = True\n",
    "        self.dataroot = 'D:/AffineGAN-master/dataset/happy'\n",
    "        self.batch_size = 1\n",
    "        self.loadSize = 286\n",
    "        self.display_winsize = 256\n",
    "        self.fineSize = 256\n",
    "        self.input_nc = 3\n",
    "        self.output_nc = 3\n",
    "        self.ngf = 64\n",
    "        self.ndf = 64\n",
    "        self.netD = 'basic'\n",
    "        self.n_layers_D = 3\n",
    "        self.netG = 'unet_256'\n",
    "        self.gpu_ids = '0'\n",
    "        self.name = 'happy'\n",
    "        self.dataset_mode = 'affineGAN'\n",
    "        self.model = 'affineGAN'\n",
    "        self.epoch = 'best'\n",
    "        self.num_threads = 1\n",
    "        self.checkpoints_dir = 'D:/AffineGAN-master/check_param'\n",
    "        self.norm = 'instance'\n",
    "        self.serial_batches = False\n",
    "        self.no_dropout = False\n",
    "        self.max_dataset_size = float(\"inf\")\n",
    "        self.resize_or_crop = 'resize_and_crop'\n",
    "        self.no_flip = False\n",
    "        self.init_type = 'normal'\n",
    "        self.init_gain = 0.02\n",
    "        self.verbose = False\n",
    "        self.suffix = ''\n",
    "        self.no_patch = False\n",
    "\n",
    "    def print_options(self):\n",
    "        message = ''\n",
    "        message += '----------------- Options ---------------\\n'\n",
    "        for k, v in sorted(vars(self).items()):\n",
    "            comment = ''\n",
    "            message += '{:>25}: {:<30}{}\\n'.format(str(k), str(v), comment)\n",
    "        message += '----------------- End -------------------'\n",
    "        print(message)\n",
    "\n",
    "        # save to the disk\n",
    "        expr_dir = os.path.join(self.checkpoints_dir, self.name)\n",
    "        util.mkdirs(expr_dir)\n",
    "        file_name = os.path.join(expr_dir, 'opt.txt')\n",
    "        with open(file_name, 'wt') as opt_file:\n",
    "            opt_file.write(message)\n",
    "            opt_file.write('\\n')\n",
    "\n",
    "    def parse(self):\n",
    "        self.print_options()\n",
    "        self.gpu_ids = [int(id) for id in self.gpu_ids.split(',') if int(id) >= 0]\n",
    "        if len(self.gpu_ids) > 0:\n",
    "            torch.cuda.set_device(self.gpu_ids[0])\n",
    "        self.initialized = True\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainParams(Params):\n",
    "    def __init__(self):\n",
    "        super(TrainParams, self).__init__()\n",
    "        self.display_freq = 100\n",
    "        self.display_ncols = 0\n",
    "        self.display_id = 1\n",
    "        self.display_server = \"http://localhost\"\n",
    "        self.display_env = \"main\"\n",
    "        self.display_port = 8097\n",
    "        self.update_html_freq = 1000\n",
    "        self.print_freq = 50\n",
    "        self.save_latest_freq = 1000\n",
    "        self.save_epoch_freq = 200\n",
    "        self.continue_train = False\n",
    "        self.epoch_count = 1\n",
    "        self.phase = \"train\"\n",
    "        self.niter = 10000\n",
    "        self.niter_decay = 100\n",
    "        self.beta1 = 0.5\n",
    "        self.lr = 0.0002\n",
    "        self.no_lsgan = False\n",
    "        self.lambda_A = 100.0\n",
    "        self.lambda_L1 = 100.0\n",
    "        self.no_html = False\n",
    "        self.lr_policy = \"lambda\"\n",
    "        self.lr_decay_iters = 50\n",
    "        self.w_pa = 1.0\n",
    "        self.w_la = 1.0\n",
    "        self.w_co = 1.0\n",
    "        self.train_imagenum = 5\n",
    "        self.isTrain = True\n",
    "\n",
    "    def initialize(self, parser):\n",
    "        parser = Params.initialize(self, parser)\n",
    "        # Add custom arguments using self.\n",
    "        self.display_freq = 100\n",
    "        self.display_ncols = 0\n",
    "        self.display_id = -1\n",
    "        self.display_server = \"http://localhost\"\n",
    "        self.display_env = \"main\"\n",
    "        self.display_port = 8097\n",
    "        self.update_html_freq = 1000\n",
    "        self.print_freq = 50\n",
    "        self.save_latest_freq = 1000\n",
    "        self.save_epoch_freq = 200\n",
    "        self.continue_train = False\n",
    "        self.epoch_count = 1\n",
    "        self.phase = \"train\"\n",
    "        self.niter = 10000\n",
    "        self.niter_decay = 100\n",
    "        self.beta1 = 0.5\n",
    "        self.lr = 0.0002\n",
    "        self.no_lsgan = False\n",
    "        self.lambda_A = 100.0\n",
    "        self.lambda_L1 = 100.0\n",
    "        self.no_html = False\n",
    "        self.lr_policy = \"lambda\"\n",
    "        self.lr_decay_iters = 50\n",
    "        self.w_pa = 1.0\n",
    "        self.w_la = 1.0\n",
    "        self.w_co = 1.0\n",
    "        self.train_imagenum = 5\n",
    "\n",
    "        return parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestParams(Params):\n",
    "    def __init__(self):\n",
    "        super(TestParams, self).__init__()\n",
    "        self.ntest = float(\"inf\")\n",
    "        self.results_dir = \"D:/AffineGAN-master/results_best\"\n",
    "        self.aspect_ratio = 1.0\n",
    "        self.phase = \"test\"\n",
    "        self.num_test = 100\n",
    "        self.interval = 0.05\n",
    "        self.eval = True\n",
    "        self.loadSize = 256\n",
    "        self.w_pa = 1.0\n",
    "        self.w_la = 1.0\n",
    "        self.w_co = 1.0\n",
    "        self.isTrain = False\n",
    "\n",
    "    def initialize(self, parser):\n",
    "        parser = Params.initialize(self, parser)\n",
    "        # Add custom arguments using self.\n",
    "        self.ntest = float(\"inf\")\n",
    "        self.results_dir = \"D:/AffineGAN-master/results_best\"\n",
    "        self.aspect_ratio = 1.0\n",
    "        self.phase = \"test\"\n",
    "        self.num_test = 100\n",
    "        self.interval = 0.05\n",
    "        self.eval = True\n",
    "        self.loadSize = 256\n",
    "        self.w_pa = 1.0\n",
    "        self.w_la = 1.0\n",
    "        self.w_co = 1.0\n",
    "\n",
    "        return parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import json\n",
    "\n",
    "def train():\n",
    "    best_loss = float('inf')  # Gi tr li tt nht\n",
    "    best_params = None\n",
    "\n",
    "    params_netD = ['basic', 'n_layers', 'pixel']\n",
    "    params_nLayerD = [1, 3, 5]\n",
    "    params_initGain = [0.01, 0.02, 0.05, 0.07, 0.1]\n",
    "    params_noPatch = [True, False]\n",
    "    params_lrPolicy = ['lambda' ,'step', 'plateau', 'cosine']\n",
    "    params_noLsgan = [True, False]\n",
    "    params_beta1 = [0.1, 0.2, 0.4, 0.3, 0,5, 0.6, 0.7]\n",
    "    params_lr = [0.0001, 0.0002, 0.0025]\n",
    "    # params_lambdaA = [30.0, 70.0, 100.0, 130.0, 150.0]\n",
    "    # params_lambdaL1 = [30.0, 70.0, 100.0, 130.0, 150.0]\n",
    "\n",
    "    param_combinations = itertools.product(params_netD, params_nLayerD, params_initGain,\n",
    "                                           params_noPatch, params_lrPolicy, params_noLsgan,\n",
    "                                           params_beta1, params_lr)\n",
    "    for params in param_combinations:\n",
    "        params_netD, params_nLayerD, params_initGain, params_noPatch, params_lrPolicy, params_noLsgan, params_beta1, params_lr = params\n",
    "        opt = TrainParams().parse()\n",
    "        opt.netD = params_netD\n",
    "        opt.n_layers_D = params_nLayerD\n",
    "        opt.init_gain = params_initGain\n",
    "        opt.no_patch = params_noPatch\n",
    "        opt.lr_policy = params_lrPolicy\n",
    "        opt.no_lsgan = params_noLsgan\n",
    "        opt.beta1 = params_beta1\n",
    "        opt.lr = params_lr\n",
    "        # opt.lambda_A = params_lambdaA\n",
    "        # opt.lambda_L1 = params_lambdaL1\n",
    "        \n",
    "        data_loader = CreateDataLoader(opt)\n",
    "        dataset = data_loader.load_data()\n",
    "        dataset_size = len(data_loader)\n",
    "        print(\"#training images = %d\" % dataset_size)\n",
    "\n",
    "        model = create_model(opt)\n",
    "        model.setup(opt)\n",
    "        visualizer = Visualizer(opt)\n",
    "        total_steps = 0\n",
    "\n",
    "        for epoch in range(opt.epoch_count, opt.niter + opt.niter_decay + 1):\n",
    "            epoch_start_time = time.time()\n",
    "            iter_data_time = time.time()\n",
    "            epoch_iter = 0\n",
    "\n",
    "            for i, data in enumerate(dataset):\n",
    "                iter_start_time = time.time()\n",
    "                visualizer.reset()\n",
    "                total_steps += opt.batch_size\n",
    "                epoch_iter += opt.batch_size\n",
    "                model.set_input(data)\n",
    "                model.optimize_parameters()\n",
    "\n",
    "                if total_steps % opt.display_freq == 0:\n",
    "                    save_result = total_steps % opt.update_html_freq == 0\n",
    "                    visualizer.display_current_results(\n",
    "                        model.get_current_visuals(), epoch, save_result\n",
    "                    )\n",
    "\n",
    "                if total_steps % opt.print_freq == 0:\n",
    "                    losses = model.get_current_losses()\n",
    "                    t = (time.time() - iter_start_time) / opt.batch_size\n",
    "                    visualizer.print_current_losses(\n",
    "                        epoch, epoch_iter, losses, t, iter_start_time - iter_data_time\n",
    "                    )\n",
    "                    if opt.display_id > 0:\n",
    "                        visualizer.plot_current_losses(\n",
    "                            epoch, float(epoch_iter) / dataset_size, opt, losses\n",
    "                        )\n",
    "\n",
    "                if total_steps % opt.save_latest_freq == 0:\n",
    "                    print(\n",
    "                        \"saving the latest model (epoch %d, total_steps %d)\"\n",
    "                        % (epoch, total_steps)\n",
    "                    )\n",
    "                    model.save_networks(\"latest\")\n",
    "\n",
    "                iter_data_time = time.time()\n",
    "            if epoch % opt.save_epoch_freq == 0:\n",
    "                print(\n",
    "                    \"saving the model at the end of epoch %d, iters %d\"\n",
    "                    % (epoch, total_steps)\n",
    "                )\n",
    "                model.save_networks(\"latest\")\n",
    "                model.save_networks(epoch)\n",
    "\n",
    "            model.update_learning_rate()\n",
    "\n",
    "            # Lu m hnh tt nht\n",
    "            if losses['G_L1'] < best_loss:\n",
    "                print(\"Saving the best model (epoch %d, total_steps %d)\" % (epoch, total_steps))\n",
    "                best_loss = losses['G_L1']\n",
    "                best_params = {'params_netD': params_netD, \n",
    "                               'params_nLayerD': params_nLayerD, \n",
    "                               'params_initGain': params_initGain,\n",
    "                               'params_noPatch': params_noPatch, \n",
    "                               'params_lrPolicy': params_lrPolicy, \n",
    "                               'params_noLsgan': params_noLsgan,\n",
    "                               'params_noLsgan': params_noLsgan, \n",
    "                               'params_beta1': params_beta1, \n",
    "                               'params_lr': params_lr}\n",
    "                # Lu thng tin v cc tham s ti u thnh file .txt\n",
    "                with open('best_params.txt', 'w') as f:\n",
    "                    json.dump(best_params, f, indent=4)\n",
    "                model.save_networks(\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate():\n",
    "    opt = TestParams().parse()\n",
    "    # hard-code some parameters for test\n",
    "    opt.num_threads = 1  # test code only supports num_threads = 1\n",
    "    opt.batch_size = 1  # test code only supports batch_size = 1\n",
    "    opt.serial_batches = True  # no shuffle\n",
    "    opt.no_flip = True  # no flip\n",
    "    opt.display_id = -1  # no visdom display\n",
    "    data_loader = CreateDataLoader(opt)\n",
    "    dataset = data_loader.load_data()\n",
    "    model = create_model(opt)\n",
    "    model.setup(opt)\n",
    "    # create a website\n",
    "    web_dir = os.path.join(opt.results_dir, opt.name, \"%s_%s\" % (opt.phase, opt.epoch))\n",
    "    webpage = html.HTML(\n",
    "        web_dir,\n",
    "        \"Experiment = %s, Phase = %s, Epoch = %s\" % (opt.name, opt.phase, opt.epoch),\n",
    "    )\n",
    "\n",
    "    if opt.eval:\n",
    "        model.eval()\n",
    "    for i, data in enumerate(dataset):\n",
    "        if i >= opt.num_test:\n",
    "            break\n",
    "        model.set_input(data)\n",
    "        model.test()\n",
    "        visuals = model.get_current_visuals()\n",
    "        img_path = model.get_image_paths()\n",
    "        if i % 5 == 0:\n",
    "            print(\"processing (%04d)-th image... %s\" % (i, img_path))\n",
    "        save_images(\n",
    "            webpage,\n",
    "            visuals,\n",
    "            img_path,\n",
    "            aspect_ratio=opt.aspect_ratio,\n",
    "            width=opt.display_winsize,\n",
    "        )\n",
    "    # save the website\n",
    "    webpage.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageToGifConverter:\n",
    "    def __init__(self, exp_names, results_dir=\"./results/\", epoch=\"best\", phase=\"test\", dataroot=None, interval=0.05):\n",
    "        self.base_output_dir = \"gifs\"\n",
    "        self.exp_list = exp_names.split(\",\")\n",
    "        self.results_dir = results_dir\n",
    "        self.epoch = epoch\n",
    "        self.phase = phase\n",
    "        self.dataroot = dataroot\n",
    "        self.interval = interval\n",
    "\n",
    "    def img2gif(self):\n",
    "        for exp_name in self.exp_list:\n",
    "            current_output_dir = os.path.join(self.results_dir, self.base_output_dir, exp_name)\n",
    "            if not os.path.exists(current_output_dir):\n",
    "                os.makedirs(current_output_dir)\n",
    "\n",
    "            for sample_idx in os.listdir(os.path.join(self.dataroot, \"test\", \"img\")):\n",
    "                filenames = []\n",
    "                images = []\n",
    "                num_str = sample_idx\n",
    "\n",
    "                for i in range(int(1 / self.interval)):\n",
    "                    c_name = os.path.join(\n",
    "                        self.results_dir,\n",
    "                        exp_name,\n",
    "                        \"%s_%s\" % (self.phase, self.epoch),\n",
    "                        \"images\",\n",
    "                        \"%s_fake_B_list%d.png\" % (num_str, i),\n",
    "                    )\n",
    "                    filenames.append(c_name)\n",
    "\n",
    "                for filename in filenames:\n",
    "                    a = np.array(imageio.imread(filename))\n",
    "                    images.append(a)\n",
    "\n",
    "                output_dir = os.path.join(\n",
    "                    current_output_dir, sample_idx + \"_\" + str(self.epoch) + \".gif\"\n",
    "                )\n",
    "                imageio.mimsave(output_dir, images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = ImageToGifConverter(exp_names=\"happy\", results_dir=\"D:/AffineGAN-master/results_best\", \n",
    "                                epoch=\"best\", phase=\"test\", dataroot=\"D:/AffineGAN-master/dataset/test_star\", interval=0.05)\n",
    "converter.img2gif()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
